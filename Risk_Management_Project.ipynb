{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ccfb159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudocode:\n",
    "# Load the necessary libraries\n",
    "# Read the dataset into a Pandas DataFrame\n",
    "# Filter the dataset to include only non-fraudulent transactions\n",
    "# Train a One-Class SVM on this filtered dataset\n",
    "# Predict \"grey area transactions\" as those where the One-Class SVM predicts an anomaly\n",
    "\n",
    "# Python code:\n",
    "import pandas as pd\n",
    "from sklearn.svm import OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9c5a63b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data1 = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "299c47f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b463bfc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28481, 31)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Take some sample of the data\n",
    "\n",
    "data= data1.sample(frac = 0.1,random_state=1)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1714b7b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e28e5028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28432, 31)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out non-fraudulent transactions\n",
    "non_fraud = data[data['Class'] == 0]\n",
    "non_fraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6a28466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done1\n",
      "done2\n",
      "done3\n",
      "done4\n"
     ]
    }
   ],
   "source": [
    "# Feature selection: Exclude 'Time' and 'Class' for training the model\n",
    "X_non_fraud = non_fraud.drop(['Time', 'Class'], axis=1)\n",
    "print('done1')\n",
    "\n",
    "# Initialize One-Class SVM model\n",
    "# Note: You'll need to adjust 'nu' parameter which is an upper bound on the fraction of training errors\n",
    "# and a lower bound of the fraction of support vectors.\n",
    "one_class_svm_non_fraud = OneClassSVM(kernel='rbf', gamma='auto', nu=0.01)\n",
    "print('done2')\n",
    "\n",
    "# Train the model\n",
    "one_class_svm_non_fraud.fit(X_non_fraud)\n",
    "print('done3')\n",
    "\n",
    "# Predict using the trained model (1 for inliers, -1 for outliers)\n",
    "# Here, we're using the entire dataset for prediction to find \"grey area transactions\"\n",
    "predictions = one_class_svm_non_fraud.predict(data.drop(['Time', 'Class'], axis=1))\n",
    "data['Grey_Non_Fraud'] = predictions\n",
    "print('done4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7a7cc053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28481,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7f27ee2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of \"grey area transactions\": 1734\n"
     ]
    }
   ],
   "source": [
    "# Count the number of \"grey area transactions\"\n",
    "grey_area_count = (data['Grey_Non_Fraud'] == -1).sum()\n",
    "\n",
    "# Print the number of \"grey area transactions\"\n",
    "print(f'Number of \"grey area transactions\": {grey_area_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "66a4cab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>Grey_Non_Fraud</th>\n",
       "      <th>SVM_Predicted_Class</th>\n",
       "      <th>Grey_Fraud</th>\n",
       "      <th>SVM_Fraud_Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169876</th>\n",
       "      <td>119907.0</td>\n",
       "      <td>-0.611712</td>\n",
       "      <td>-0.769705</td>\n",
       "      <td>-0.149759</td>\n",
       "      <td>-0.224877</td>\n",
       "      <td>2.028577</td>\n",
       "      <td>-2.019887</td>\n",
       "      <td>0.292491</td>\n",
       "      <td>-0.523020</td>\n",
       "      <td>0.358468</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.220686</td>\n",
       "      <td>-0.201146</td>\n",
       "      <td>0.066501</td>\n",
       "      <td>0.221180</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127467</th>\n",
       "      <td>78340.0</td>\n",
       "      <td>-0.814682</td>\n",
       "      <td>1.319219</td>\n",
       "      <td>1.329415</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>-0.284871</td>\n",
       "      <td>-0.653985</td>\n",
       "      <td>0.321552</td>\n",
       "      <td>0.435975</td>\n",
       "      <td>-0.704298</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.261034</td>\n",
       "      <td>0.080621</td>\n",
       "      <td>0.162427</td>\n",
       "      <td>0.059456</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137900</th>\n",
       "      <td>82382.0</td>\n",
       "      <td>-0.318193</td>\n",
       "      <td>1.118618</td>\n",
       "      <td>0.969864</td>\n",
       "      <td>-0.127052</td>\n",
       "      <td>0.569563</td>\n",
       "      <td>-0.532484</td>\n",
       "      <td>0.706252</td>\n",
       "      <td>-0.064966</td>\n",
       "      <td>-0.463271</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018148</td>\n",
       "      <td>0.121679</td>\n",
       "      <td>0.249050</td>\n",
       "      <td>0.092516</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21513</th>\n",
       "      <td>31717.0</td>\n",
       "      <td>-1.328271</td>\n",
       "      <td>1.018378</td>\n",
       "      <td>1.775426</td>\n",
       "      <td>-1.574193</td>\n",
       "      <td>-0.117696</td>\n",
       "      <td>-0.457733</td>\n",
       "      <td>0.681867</td>\n",
       "      <td>-0.031641</td>\n",
       "      <td>0.383872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232829</td>\n",
       "      <td>0.814177</td>\n",
       "      <td>0.098797</td>\n",
       "      <td>-0.004273</td>\n",
       "      <td>15.98</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134700</th>\n",
       "      <td>80923.0</td>\n",
       "      <td>1.276712</td>\n",
       "      <td>0.617120</td>\n",
       "      <td>-0.578014</td>\n",
       "      <td>0.879173</td>\n",
       "      <td>0.061706</td>\n",
       "      <td>-1.472002</td>\n",
       "      <td>0.373692</td>\n",
       "      <td>-0.287204</td>\n",
       "      <td>-0.084482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.552170</td>\n",
       "      <td>0.370701</td>\n",
       "      <td>-0.034255</td>\n",
       "      <td>0.041709</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "169876  119907.0 -0.611712 -0.769705 -0.149759 -0.224877  2.028577 -2.019887   \n",
       "127467   78340.0 -0.814682  1.319219  1.329415  0.027273 -0.284871 -0.653985   \n",
       "137900   82382.0 -0.318193  1.118618  0.969864 -0.127052  0.569563 -0.532484   \n",
       "21513    31717.0 -1.328271  1.018378  1.775426 -1.574193 -0.117696 -0.457733   \n",
       "134700   80923.0  1.276712  0.617120 -0.578014  0.879173  0.061706 -1.472002   \n",
       "\n",
       "              V7        V8        V9  ...       V25       V26       V27  \\\n",
       "169876  0.292491 -0.523020  0.358468  ... -2.220686 -0.201146  0.066501   \n",
       "127467  0.321552  0.435975 -0.704298  ... -0.261034  0.080621  0.162427   \n",
       "137900  0.706252 -0.064966 -0.463271  ... -0.018148  0.121679  0.249050   \n",
       "21513   0.681867 -0.031641  0.383872  ...  0.232829  0.814177  0.098797   \n",
       "134700  0.373692 -0.287204 -0.084482  ...  0.552170  0.370701 -0.034255   \n",
       "\n",
       "             V28  Amount  Class  Grey_Non_Fraud  SVM_Predicted_Class  \\\n",
       "169876  0.221180    1.79      0               1                    0   \n",
       "127467  0.059456    1.98      0               1                    0   \n",
       "137900  0.092516    0.89      0               1                    0   \n",
       "21513  -0.004273   15.98      0               1                    0   \n",
       "134700  0.041709    0.76      0               1                    0   \n",
       "\n",
       "        Grey_Fraud  SVM_Fraud_Pred  \n",
       "169876          -1               1  \n",
       "127467          -1               1  \n",
       "137900          -1               1  \n",
       "21513           -1               1  \n",
       "134700          -1               1  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e192346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8e2049e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3388\\210516681.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgrey_area\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Class'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Grey_Non_Fraud'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfiltered_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgrey_area\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1517\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1518\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1519\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   1520\u001b[0m             \u001b[1;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1521\u001b[0m             \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1522\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "grey_area = (data['Class'] == 1 and data['Grey_Non_Fraud'] == -1)\n",
    "filtered_data = data[grey_area]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f7524474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 35)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0ce7a9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for One-Class SVM: 0.9403\n",
      "Classification Report for One-Class SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97     28432\n",
      "           1       0.02      0.86      0.05        49\n",
      "\n",
      "    accuracy                           0.94     28481\n",
      "   macro avg       0.51      0.90      0.51     28481\n",
      "weighted avg       1.00      0.94      0.97     28481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data['SVM_Predicted_Class'] = data['Grey_Non_Fraud'].apply(lambda x: 1 if x == -1 else 0)\n",
    "\n",
    "# Actual class labels of the entire dataset\n",
    "Y_true = data['Class']\n",
    "\n",
    "# Predicted class labels from One-Class SVM\n",
    "Y_pred_svm = data['SVM_Predicted_Class']\n",
    "\n",
    "# Calculate the accuracy score for the One-Class SVM\n",
    "svm_accuracy = accuracy_score(Y_true, Y_pred_svm)\n",
    "\n",
    "# Generate a classification report for the One-Class SVM\n",
    "svm_class_report = classification_report(Y_true, Y_pred_svm)\n",
    "\n",
    "# Print the accuracy score and classification report\n",
    "print(f'Accuracy Score for One-Class SVM: {svm_accuracy:.4f}')\n",
    "print('Classification Report for One-Class SVM:')\n",
    "print(svm_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21092baa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate the total number of \"grey area transactions\" where the prediction is -1 (outliers marked as 1)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m total_grey_area_transactions \u001b[38;5;241m=\u001b[39m (data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSVM_Predicted_Class\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Find the total number of fraudulent transactions in the dataset\u001b[39;00m\n\u001b[0;32m      5\u001b[0m total_fraudulent_transactions \u001b[38;5;241m=\u001b[39m (data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate the total number of \"grey area transactions\" where the prediction is -1 (outliers marked as 1)\n",
    "total_grey_area_transactions = (data['SVM_Predicted_Class'] == 1).sum()\n",
    "\n",
    "# Find the total number of fraudulent transactions in the dataset\n",
    "total_fraudulent_transactions = (data['Class'] == 1).sum()\n",
    "\n",
    "# Calculate the percentage of \"grey area transactions\" relative to the total number of fraudulent transactions\n",
    "percentage_grey_area_transactions = (total_grey_area_transactions / total_fraudulent_transactions) \n",
    "\n",
    "# Print the total and the percentage of \"grey area transactions\"\n",
    "print(f'Total number of \"grey area transactions\": {total_grey_area_transactions}')\n",
    "print(f'Percentage of \"grey area transactions\" relative to total fraudulent transactions: {percentage_grey_area_transactions:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "511f9adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>Grey_Non_Fraud</th>\n",
       "      <th>SVM_Predicted_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169876</th>\n",
       "      <td>119907.0</td>\n",
       "      <td>-0.611712</td>\n",
       "      <td>-0.769705</td>\n",
       "      <td>-0.149759</td>\n",
       "      <td>-0.224877</td>\n",
       "      <td>2.028577</td>\n",
       "      <td>-2.019887</td>\n",
       "      <td>0.292491</td>\n",
       "      <td>-0.523020</td>\n",
       "      <td>0.358468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380739</td>\n",
       "      <td>0.023440</td>\n",
       "      <td>-2.220686</td>\n",
       "      <td>-0.201146</td>\n",
       "      <td>0.066501</td>\n",
       "      <td>0.221180</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127467</th>\n",
       "      <td>78340.0</td>\n",
       "      <td>-0.814682</td>\n",
       "      <td>1.319219</td>\n",
       "      <td>1.329415</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>-0.284871</td>\n",
       "      <td>-0.653985</td>\n",
       "      <td>0.321552</td>\n",
       "      <td>0.435975</td>\n",
       "      <td>-0.704298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090660</td>\n",
       "      <td>0.401147</td>\n",
       "      <td>-0.261034</td>\n",
       "      <td>0.080621</td>\n",
       "      <td>0.162427</td>\n",
       "      <td>0.059456</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137900</th>\n",
       "      <td>82382.0</td>\n",
       "      <td>-0.318193</td>\n",
       "      <td>1.118618</td>\n",
       "      <td>0.969864</td>\n",
       "      <td>-0.127052</td>\n",
       "      <td>0.569563</td>\n",
       "      <td>-0.532484</td>\n",
       "      <td>0.706252</td>\n",
       "      <td>-0.064966</td>\n",
       "      <td>-0.463271</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.123884</td>\n",
       "      <td>-0.495687</td>\n",
       "      <td>-0.018148</td>\n",
       "      <td>0.121679</td>\n",
       "      <td>0.249050</td>\n",
       "      <td>0.092516</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21513</th>\n",
       "      <td>31717.0</td>\n",
       "      <td>-1.328271</td>\n",
       "      <td>1.018378</td>\n",
       "      <td>1.775426</td>\n",
       "      <td>-1.574193</td>\n",
       "      <td>-0.117696</td>\n",
       "      <td>-0.457733</td>\n",
       "      <td>0.681867</td>\n",
       "      <td>-0.031641</td>\n",
       "      <td>0.383872</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.239197</td>\n",
       "      <td>0.009967</td>\n",
       "      <td>0.232829</td>\n",
       "      <td>0.814177</td>\n",
       "      <td>0.098797</td>\n",
       "      <td>-0.004273</td>\n",
       "      <td>15.98</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134700</th>\n",
       "      <td>80923.0</td>\n",
       "      <td>1.276712</td>\n",
       "      <td>0.617120</td>\n",
       "      <td>-0.578014</td>\n",
       "      <td>0.879173</td>\n",
       "      <td>0.061706</td>\n",
       "      <td>-1.472002</td>\n",
       "      <td>0.373692</td>\n",
       "      <td>-0.287204</td>\n",
       "      <td>-0.084482</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.076738</td>\n",
       "      <td>0.258708</td>\n",
       "      <td>0.552170</td>\n",
       "      <td>0.370701</td>\n",
       "      <td>-0.034255</td>\n",
       "      <td>0.041709</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "169876  119907.0 -0.611712 -0.769705 -0.149759 -0.224877  2.028577 -2.019887   \n",
       "127467   78340.0 -0.814682  1.319219  1.329415  0.027273 -0.284871 -0.653985   \n",
       "137900   82382.0 -0.318193  1.118618  0.969864 -0.127052  0.569563 -0.532484   \n",
       "21513    31717.0 -1.328271  1.018378  1.775426 -1.574193 -0.117696 -0.457733   \n",
       "134700   80923.0  1.276712  0.617120 -0.578014  0.879173  0.061706 -1.472002   \n",
       "\n",
       "              V7        V8        V9  ...       V23       V24       V25  \\\n",
       "169876  0.292491 -0.523020  0.358468  ...  0.380739  0.023440 -2.220686   \n",
       "127467  0.321552  0.435975 -0.704298  ...  0.090660  0.401147 -0.261034   \n",
       "137900  0.706252 -0.064966 -0.463271  ... -0.123884 -0.495687 -0.018148   \n",
       "21513   0.681867 -0.031641  0.383872  ... -0.239197  0.009967  0.232829   \n",
       "134700  0.373692 -0.287204 -0.084482  ... -0.076738  0.258708  0.552170   \n",
       "\n",
       "             V26       V27       V28  Amount  Class  Grey_Non_Fraud  \\\n",
       "169876 -0.201146  0.066501  0.221180    1.79      0               1   \n",
       "127467  0.080621  0.162427  0.059456    1.98      0               1   \n",
       "137900  0.121679  0.249050  0.092516    0.89      0               1   \n",
       "21513   0.814177  0.098797 -0.004273   15.98      0               1   \n",
       "134700  0.370701 -0.034255  0.041709    0.76      0               1   \n",
       "\n",
       "        SVM_Predicted_Class  \n",
       "169876                    0  \n",
       "127467                    0  \n",
       "137900                    0  \n",
       "21513                     0  \n",
       "134700                    0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7358643c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done1\n",
      "done2\n",
      "done3\n",
      "done4\n",
      "done5\n"
     ]
    }
   ],
   "source": [
    "# Pseudocode:\n",
    "# Filter the dataset to include only fraudulent transactions\n",
    "# Train a One-Class SVM on this filtered dataset\n",
    "# Predict \"grey area transactions\" as those where the One-Class SVM predicts an anomaly\n",
    "\n",
    "# Python code:\n",
    "# Filter out fraudulent transactions\n",
    "fraud = data[data['Class'] == 1]\n",
    "print('done1')\n",
    "\n",
    "# Feature selection: Exclude 'Time' and 'Class' for training the model\n",
    "X_fraud = fraud.drop(['Time', 'Class'], axis=1)\n",
    "print('done2')\n",
    "\n",
    "# Initialize One-Class SVM model\n",
    "one_class_svm_fraud = OneClassSVM(kernel='rbf', gamma='auto', nu=0.01)\n",
    "print('done3')\n",
    "\n",
    "# Train the model on fraudulent data\n",
    "one_class_svm_fraud.fit(X_fraud)\n",
    "print('done4')\n",
    "\n",
    "# Predict using the trained model (1 for inliers, -1 for outliers)\n",
    "# Here, we're using the entire dataset for prediction to find \"grey area transactions\"\n",
    "fraud_predictions = one_class_svm_fraud.predict(data.drop(['Time', 'Class'], axis=1))\n",
    "data['Grey_Fraud'] = fraud_predictions\n",
    "print('done5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d131a601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for One-Class SVM trained on Fraud: 0.0013\n",
      "Classification Report for One-Class SVM trained on Fraud:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.00      0.00     28432\n",
      "           1       0.00      0.45      0.00        49\n",
      "\n",
      "    accuracy                           0.00     28481\n",
      "   macro avg       0.19      0.22      0.00     28481\n",
      "weighted avg       0.37      0.00      0.00     28481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# The model is trained on fraud, so it considers -1 as fraudulent (positive class)\n",
    "# Map the model predictions to match the original class labels\n",
    "# SVM prediction: -1 (anomaly) corresponds to 1 (fraud) in original data\n",
    "# SVM prediction: 1 (normal) corresponds to 0 (non-fraud) in original data\n",
    "data['SVM_Fraud_Pred'] = data['Grey_Fraud'].apply(lambda x: 1 if x == -1 else 0)\n",
    "\n",
    "# True class labels from the dataset\n",
    "Y_true = data['Class']\n",
    "\n",
    "# Predicted class labels from the One-Class SVM trained on fraud\n",
    "Y_pred_fraud_svm = data['SVM_Fraud_Pred']\n",
    "\n",
    "# Calculate the accuracy score for the One-Class SVM model on the entire dataset\n",
    "fraud_svm_accuracy = accuracy_score(Y_true, Y_pred_fraud_svm)\n",
    "\n",
    "# Generate the classification report for the One-Class SVM model on the entire dataset\n",
    "fraud_svm_class_report = classification_report(Y_true, Y_pred_fraud_svm)\n",
    "\n",
    "# Print the accuracy score and classification report\n",
    "print(f'Accuracy Score for One-Class SVM trained on Fraud: {fraud_svm_accuracy:.4f}')\n",
    "print('Classification Report for One-Class SVM trained on Fraud:')\n",
    "print(fraud_svm_class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f642162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28481,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2910ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(28460, 35)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify \"grey area transactions\" as those where either model predicted -1\n",
    "grey_area = data[(data['Grey_Non_Fraud'] == -1) | (data['Grey_Fraud'] == -1)]\n",
    "print('done1')\n",
    "grey_area.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cf76e01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>Grey_Non_Fraud</th>\n",
       "      <th>SVM_Predicted_Class</th>\n",
       "      <th>Grey_Fraud</th>\n",
       "      <th>SVM_Fraud_Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169876</th>\n",
       "      <td>119907.0</td>\n",
       "      <td>-0.611712</td>\n",
       "      <td>-0.769705</td>\n",
       "      <td>-0.149759</td>\n",
       "      <td>-0.224877</td>\n",
       "      <td>2.028577</td>\n",
       "      <td>-2.019887</td>\n",
       "      <td>0.292491</td>\n",
       "      <td>-0.523020</td>\n",
       "      <td>0.358468</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.220686</td>\n",
       "      <td>-0.201146</td>\n",
       "      <td>0.066501</td>\n",
       "      <td>0.221180</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127467</th>\n",
       "      <td>78340.0</td>\n",
       "      <td>-0.814682</td>\n",
       "      <td>1.319219</td>\n",
       "      <td>1.329415</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>-0.284871</td>\n",
       "      <td>-0.653985</td>\n",
       "      <td>0.321552</td>\n",
       "      <td>0.435975</td>\n",
       "      <td>-0.704298</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.261034</td>\n",
       "      <td>0.080621</td>\n",
       "      <td>0.162427</td>\n",
       "      <td>0.059456</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137900</th>\n",
       "      <td>82382.0</td>\n",
       "      <td>-0.318193</td>\n",
       "      <td>1.118618</td>\n",
       "      <td>0.969864</td>\n",
       "      <td>-0.127052</td>\n",
       "      <td>0.569563</td>\n",
       "      <td>-0.532484</td>\n",
       "      <td>0.706252</td>\n",
       "      <td>-0.064966</td>\n",
       "      <td>-0.463271</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018148</td>\n",
       "      <td>0.121679</td>\n",
       "      <td>0.249050</td>\n",
       "      <td>0.092516</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21513</th>\n",
       "      <td>31717.0</td>\n",
       "      <td>-1.328271</td>\n",
       "      <td>1.018378</td>\n",
       "      <td>1.775426</td>\n",
       "      <td>-1.574193</td>\n",
       "      <td>-0.117696</td>\n",
       "      <td>-0.457733</td>\n",
       "      <td>0.681867</td>\n",
       "      <td>-0.031641</td>\n",
       "      <td>0.383872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232829</td>\n",
       "      <td>0.814177</td>\n",
       "      <td>0.098797</td>\n",
       "      <td>-0.004273</td>\n",
       "      <td>15.98</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134700</th>\n",
       "      <td>80923.0</td>\n",
       "      <td>1.276712</td>\n",
       "      <td>0.617120</td>\n",
       "      <td>-0.578014</td>\n",
       "      <td>0.879173</td>\n",
       "      <td>0.061706</td>\n",
       "      <td>-1.472002</td>\n",
       "      <td>0.373692</td>\n",
       "      <td>-0.287204</td>\n",
       "      <td>-0.084482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.552170</td>\n",
       "      <td>0.370701</td>\n",
       "      <td>-0.034255</td>\n",
       "      <td>0.041709</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "169876  119907.0 -0.611712 -0.769705 -0.149759 -0.224877  2.028577 -2.019887   \n",
       "127467   78340.0 -0.814682  1.319219  1.329415  0.027273 -0.284871 -0.653985   \n",
       "137900   82382.0 -0.318193  1.118618  0.969864 -0.127052  0.569563 -0.532484   \n",
       "21513    31717.0 -1.328271  1.018378  1.775426 -1.574193 -0.117696 -0.457733   \n",
       "134700   80923.0  1.276712  0.617120 -0.578014  0.879173  0.061706 -1.472002   \n",
       "\n",
       "              V7        V8        V9  ...       V25       V26       V27  \\\n",
       "169876  0.292491 -0.523020  0.358468  ... -2.220686 -0.201146  0.066501   \n",
       "127467  0.321552  0.435975 -0.704298  ... -0.261034  0.080621  0.162427   \n",
       "137900  0.706252 -0.064966 -0.463271  ... -0.018148  0.121679  0.249050   \n",
       "21513   0.681867 -0.031641  0.383872  ...  0.232829  0.814177  0.098797   \n",
       "134700  0.373692 -0.287204 -0.084482  ...  0.552170  0.370701 -0.034255   \n",
       "\n",
       "             V28  Amount  Class  Grey_Non_Fraud  SVM_Predicted_Class  \\\n",
       "169876  0.221180    1.79      0               1                    0   \n",
       "127467  0.059456    1.98      0               1                    0   \n",
       "137900  0.092516    0.89      0               1                    0   \n",
       "21513  -0.004273   15.98      0               1                    0   \n",
       "134700  0.041709    0.76      0               1                    0   \n",
       "\n",
       "        Grey_Fraud  SVM_Fraud_Pred  \n",
       "169876          -1               1  \n",
       "127467          -1               1  \n",
       "137900          -1               1  \n",
       "21513           -1               1  \n",
       "134700          -1               1  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grey_area.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cff34399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done2\n",
      "done3\n",
      "done4\n",
      "done5\n",
      "Accuracy Score: 0.9991\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5684\n",
      "           1       0.71      0.62      0.67         8\n",
      "\n",
      "    accuracy                           1.00      5692\n",
      "   macro avg       0.86      0.81      0.83      5692\n",
      "weighted avg       1.00      1.00      1.00      5692\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pseudocode:\n",
    "# Combine the \"grey area transactions\" from non-fraudulent and fraudulent predictions\n",
    "# Label them correctly using the original dataset\n",
    "# Train a Random Forest classifier to distinguish between legitimate and fraudulent transactions\n",
    "\n",
    "# Python code:\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Labels for \"grey area transactions\"\n",
    "Y_grey = grey_area['Class']\n",
    "X_grey = grey_area.drop(['Time', 'Class', 'Grey_Non_Fraud', 'SVM_Predicted_Class', 'Grey_Fraud', 'SVM_Fraud_Pred'], axis=1)\n",
    "print('done2')\n",
    "# Split the \"grey area transactions\" into training and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_grey, Y_grey, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "print('done3')\n",
    "# Train the model\n",
    "random_forest.fit(X_train, Y_train)\n",
    "print('done4')\n",
    "# Predict on the test set\n",
    "rf_predictions = random_forest.predict(X_test)\n",
    "print('done5')\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(Y_test, rf_predictions)\n",
    "print(f'Accuracy Score: {accuracy:.4f}')\n",
    "print(classification_report(Y_test, rf_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "67772101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9991\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Print the accuracy score\n",
    "print(f'Accuracy Score: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6affb499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a13b3039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for the Entire Dataset: 0.9993\n",
      "Classification Report for the Entire Dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    284315\n",
      "           1       0.92      0.68      0.78       492\n",
      "\n",
      "    accuracy                           1.00    284807\n",
      "   macro avg       0.96      0.84      0.89    284807\n",
      "weighted avg       1.00      1.00      1.00    284807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary functions\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Predict on the entire dataset (excluding 'Time', 'Class', and the 'Grey' columns)\n",
    "full_data_predictions = random_forest.predict(data1.drop(['Time', 'Class'], axis=1))\n",
    "\n",
    "# Actual class labels of the entire dataset\n",
    "Y_full = data1['Class']\n",
    "\n",
    "# Calculate the accuracy score for the entire dataset\n",
    "full_data_accuracy = accuracy_score(Y_full, full_data_predictions)\n",
    "\n",
    "# Generate a classification report for the entire dataset\n",
    "full_data_class_report = classification_report(Y_full, full_data_predictions)\n",
    "\n",
    "# Print the accuracy score and classification report\n",
    "print(f'Accuracy Score for the Entire Dataset: {full_data_accuracy:.4f}')\n",
    "print('Classification Report for the Entire Dataset:')\n",
    "print(full_data_class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5598f0e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Grey_Non_Fraud', 'Grey_Fraud'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ensure that the same features used for training are used for prediction\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Exclude any additional columns that were not part of the training set\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m X_full \u001b[38;5;241m=\u001b[39m data3\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGrey_Non_Fraud\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGrey_Fraud\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m X_train_columns \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Only select the columns that were used during model training\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5344\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5197\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5198\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5205\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5206\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5208\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5209\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5342\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5343\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   5345\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5346\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5347\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5348\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5349\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5350\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5351\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   5352\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4709\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4711\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4751\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4753\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4754\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4756\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7000\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7000\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7001\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7002\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Grey_Non_Fraud', 'Grey_Fraud'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Ensure that the same features used for training are used for prediction\n",
    "# Exclude any additional columns that were not part of the training set\n",
    "#X_full = data3.drop(['Time', 'Class', 'Grey_Non_Fraud', 'Grey_Fraud'], axis=1)\n",
    "X_train_columns = X_train.columns.tolist()\n",
    "\n",
    "# Only select the columns that were used during model training\n",
    "X_full = X_full[X_train_columns]\n",
    "\n",
    "# Predict on the entire dataset using the correct set of features\n",
    "full_data_predictions = random_forest.predict(X_full)\n",
    "\n",
    "# The rest of the code remains the same\n",
    "Y_full = data3['Class']\n",
    "full_data_accuracy = accuracy_score(Y_full, full_data_predictions)\n",
    "full_data_class_report = classification_report(Y_full, full_data_predictions)\n",
    "\n",
    "print(f'Accuracy Score for the Entire Dataset: {full_data_accuracy:.4f}')\n",
    "print('Classification Report for the Entire Dataset:')\n",
    "print(full_data_class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d3b74bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3= data1.sample(frac = 1.0,random_state=1)\n",
    "\n",
    "\n",
    "data3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f92757f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9994\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    284315\n",
      "           1       0.90      0.71      0.79       492\n",
      "\n",
      "    accuracy                           1.00    284807\n",
      "   macro avg       0.95      0.85      0.90    284807\n",
      "weighted avg       1.00      1.00      1.00    284807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the new dataset\n",
    "# Assuming the data is in a CSV file called 'new_creditcard_data.csv'\n",
    "new_data = data3\n",
    "\n",
    "# Prepare the feature matrix X by dropping the 'Time' and 'Class' columns\n",
    "X_new = new_data.drop(['Time', 'Class'], axis=1)\n",
    "\n",
    "# Prepare the true labels Y\n",
    "Y_new = new_data['Class']\n",
    "\n",
    "# Use the pre-trained Random Forest model to make predictions\n",
    "# Make sure the pre-trained model is named `random_forest` and is already loaded\n",
    "new_predictions = random_forest.predict(X_new)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "new_accuracy = accuracy_score(Y_new, new_predictions)\n",
    "\n",
    "# Generate a classification report\n",
    "new_class_report = classification_report(Y_new, new_predictions)\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy Score: {new_accuracy:.4f}')\n",
    "print('Classification Report:')\n",
    "print(new_class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ba8bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00c2ee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ff4085",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('path_to_data6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acd58470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28481, 31)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Take some sample of the data\n",
    "\n",
    "data6= data1.sample(frac = 0.1,random_state=1)\n",
    "\n",
    "data6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc9e7516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5690\n",
      "           1       0.67      0.57      0.62         7\n",
      "\n",
      "    accuracy                           1.00      5697\n",
      "   macro avg       0.83      0.79      0.81      5697\n",
      "weighted avg       1.00      1.00      1.00      5697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming 'data6' is already loaded as a DataFrame.\n",
    "# Replace this line with the code to load your data if needed\n",
    "# data6 = pd.read_csv('path_to_data6.csv')\n",
    "\n",
    "# Separate features and target\n",
    "X = data6.iloc[:, :-1]  # all columns except the last\n",
    "y = data6.iloc[:, -1]   # last column\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the Random Forest model\n",
    "random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = random_forest_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Print the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03f227d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5691\n",
      "           1       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           1.00      5697\n",
      "   macro avg       0.92      0.92      0.92      5697\n",
      "weighted avg       1.00      1.00      1.00      5697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "#data = pd.read_csv('dataset6.csv')  # Adjust path if needed\n",
    "\n",
    "# Assuming the last column is the target and the rest are features\n",
    "X = data6.iloc[:, :-1]\n",
    "y = data6.iloc[:, -1]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train_s, x_test, y_train_s, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Create the Random Forest Classifier with specified hyperparameters\n",
    "rand_f = RandomForestClassifier(\n",
    "    n_estimators=1000,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='auto',\n",
    "    max_leaf_nodes=None,\n",
    "    oob_score=True,\n",
    "    n_jobs=-1,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "# Fit the model on the training data\n",
    "rand_f.fit(x_train_s, y_train_s)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rand_f.predict(x_test)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix using seaborn's heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\", fmt='g')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63210058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done1\n",
      "done2\n",
      "done3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done4\n",
      "done5\n",
      "Accuracy Score: 0.9991\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5684\n",
      "           1       0.71      0.62      0.67         8\n",
      "\n",
      "    accuracy                           1.00      5692\n",
      "   macro avg       0.86      0.81      0.83      5692\n",
      "weighted avg       1.00      1.00      1.00      5692\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pseudocode:\n",
    "# Combine the \"grey area transactions\" from non-fraudulent and fraudulent predictions\n",
    "# Label them correctly using the original dataset\n",
    "# Train a Random Forest classifier to distinguish between legitimate and fraudulent transactions\n",
    "\n",
    "# Python code:\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Identify \"grey area transactions\" as those where either model predicted -1\n",
    "grey_area = data[(data['Grey_Non_Fraud'] == -1) | (data['Grey_Fraud'] == -1)]\n",
    "print('done1')\n",
    "grey_area.shape\n",
    "\n",
    "\n",
    "\n",
    "# Labels for \"grey area transactions\"\n",
    "Y_grey = grey_area['Class']\n",
    "X_grey = grey_area.drop(['Time', 'Class', 'Grey_Non_Fraud', 'Grey_Fraud'], axis=1)\n",
    "print('done2')\n",
    "# Split the \"grey area transactions\" into training and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_grey, Y_grey, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the Random Forest Classifier with specified hyperparameters\n",
    "random_forest = RandomForestClassifier(\n",
    "    n_estimators=1000,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='auto',\n",
    "    max_leaf_nodes=None,\n",
    "    oob_score=True,\n",
    "    n_jobs=-1,\n",
    "    random_state=1\n",
    ")\n",
    "print('done3')\n",
    "# Train the model\n",
    "random_forest.fit(X_train, Y_train)\n",
    "print('done4')\n",
    "# Predict on the test set\n",
    "rf_predictions = random_forest.predict(X_test)\n",
    "print('done5')\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(Y_test, rf_predictions)\n",
    "print(f'Accuracy Score: {accuracy:.4f}')\n",
    "print(classification_report(Y_test, rf_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f66aa7a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- SVM_Fraud_Pred\n- SVM_Predicted_Class\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 16\u001b[0m\n\u001b[0;32m     12\u001b[0m Y_new \u001b[38;5;241m=\u001b[39m new_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Use the pre-trained Random Forest model to make predictions\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Make sure the pre-trained model is named `random_forest` and is already loaded\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m new_predictions \u001b[38;5;241m=\u001b[39m random_forest\u001b[38;5;241m.\u001b[39mpredict(X_new)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Calculate the accuracy score\u001b[39;00m\n\u001b[0;32m     19\u001b[0m new_accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(Y_new, new_predictions)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:820\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    799\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    800\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 820\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    823\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:862\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    860\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    861\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 862\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X)\n\u001b[0;32m    864\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    865\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:602\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    601\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 602\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, dtype\u001b[38;5;241m=\u001b[39mDTYPE, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:548\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    484\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    485\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    490\u001b[0m ):\n\u001b[0;32m    491\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \n\u001b[0;32m    493\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 548\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    551\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    552\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    553\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    554\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:481\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    477\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    478\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    479\u001b[0m     )\n\u001b[1;32m--> 481\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- SVM_Fraud_Pred\n- SVM_Predicted_Class\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the new dataset\n",
    "# Assuming the data is in a CSV file called 'new_creditcard_data.csv'\n",
    "new_data = data6\n",
    "\n",
    "# Prepare the feature matrix X by dropping the 'Time' and 'Class' columns\n",
    "X_new = new_data.drop(['Time', 'Class'], axis=1)\n",
    "\n",
    "# Prepare the true labels Y\n",
    "Y_new = new_data['Class']\n",
    "\n",
    "# Use the pre-trained Random Forest model to make predictions\n",
    "# Make sure the pre-trained model is named `random_forest` and is already loaded\n",
    "new_predictions = random_forest.predict(X_new)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "new_accuracy = accuracy_score(Y_new, new_predictions)\n",
    "\n",
    "# Generate a classification report\n",
    "new_class_report = classification_report(Y_new, new_predictions)\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy Score: {new_accuracy:.4f}')\n",
    "print('Classification Report:')\n",
    "print(new_class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4048c844",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing features in the new dataset: ['Feature1', 'Feature2', 'SVM_Fraud_Pred', 'SVM_Predicted_Class']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m missing_features \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m expected_features \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m new_data\u001b[38;5;241m.\u001b[39mcolumns]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_features:\n\u001b[1;32m---> 12\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing features in the new dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Prepare the feature matrix X by dropping the 'Time' and 'Class' columns\u001b[39;00m\n\u001b[0;32m     15\u001b[0m X_new \u001b[38;5;241m=\u001b[39m new_data\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Missing features in the new dataset: ['Feature1', 'Feature2', 'SVM_Fraud_Pred', 'SVM_Predicted_Class']"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the new dataset\n",
    "new_data = data6\n",
    "\n",
    "# Check if the expected features are present\n",
    "expected_features = ['Feature1', 'Feature2', 'SVM_Fraud_Pred', 'SVM_Predicted_Class']  # add all other features used during training\n",
    "missing_features = [f for f in expected_features if f not in new_data.columns]\n",
    "\n",
    "if missing_features:\n",
    "    raise ValueError(f'Missing features in the new dataset: {missing_features}')\n",
    "\n",
    "# Prepare the feature matrix X by dropping the 'Time' and 'Class' columns\n",
    "X_new = new_data.drop(['Time', 'Class'], axis=1)\n",
    "\n",
    "# Prepare the true labels Y\n",
    "Y_new = new_data['Class']\n",
    "\n",
    "# Use the pre-trained Random Forest model to make predictions\n",
    "new_predictions = random_forest.predict(X_new)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "new_accuracy = accuracy_score(Y_new, new_predictions)\n",
    "\n",
    "# Generate a classification report\n",
    "new_class_report = classification_report(Y_new, new_predictions)\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy Score: {new_accuracy:.4f}')\n",
    "print('Classification Report:')\n",
    "print(new_class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed67f37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21ec9de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
